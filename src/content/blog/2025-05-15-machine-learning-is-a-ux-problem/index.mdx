---
title: "Machine Learning Is a UX Problem"
date: 2025-05-15
draft: false
tags:
  - machine-learning
  - ux
  - data-science
description: "Data scientists obsess over precision and F1 scores while neglecting how outputs are presented to users. Great models that nobody uses."
---

That title is deliberately provocative, but bear with me -- I've been banging on about this for years. There is still a tendency among data scientists to get lost in the technicalities and mathematics of a problem, to strive for the greatest precision or F1 score on a model.

Ok, that's great, but people need to realise that that kind of activity comes in the tail of the problem. I've seen months of effort ploughed into sophisticated models that solve complex classification problems with phenomenal precision, far beyond what a human can achieve. And then it's presented to the user as a single "score" with no context, and lo and behold they don't use them.

Or let's say you create a model to score support cases by likely difficulty to help support agents prioritise. It does a great job, but since they already have far too many tickets per agent, you are solving the wrong problem - and just adding more crap on to the pile.

The point always comes back to - empathise with your users, talk to them, understand them and their problems. That's where your effort needs to be invested. You might even find you don't need to solve their problem with ML. You won't know until you look.
