{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/recursive-statistics-for-data-streams","result":{"data":{"post":{"__typename":"MdxPost","slug":"/recursive-statistics-for-data-streams","title":"Recursive statistics for data streams","date":"17.01.2018","tags":[{"name":"statistics","slug":"statistics"},{"name":"data-science","slug":"data-science"}],"description":null,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Recursive statistics for data streams\",\n  \"date\": \"2018-01-17T00:00:00.000Z\",\n  \"slug\": \"/recursive-statistics-for-data-streams\",\n  \"tags\": [\"statistics\", \"data-science\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"If you ever have to process an indeterminate length stream of data, it's useful to be able to compute some basic statistics as you go. The key phrase there is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"as you go\"), \" - we could easily compute a mean of an arbitrary number of samples $N$\"), mdx(\"p\", null, \"$$ \\\\bar{x} = \\\\frac{1}{N} \\\\sum_{i=1}^N x\", \"_\", \"i $$\"), mdx(\"p\", null, \"but that means we have to keep $N$ examples in memory! That's $O(N)$ space complexity, which for very a large $N$ is unacceptable.\"), mdx(\"h4\", null, \"Recursive mean\"), mdx(\"p\", null, \"Fortunately, we can compute the recursive mean given\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The previous mean $\\\\bar{x}_{i-1}$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The most recent example $x_i$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The number of examples observed so far $i$\")), mdx(\"p\", null, \"Then all we need to do is as follows. (Note that the use of $i-1$ is \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://en.wikipedia.org/wiki/Bessel%27s_correction\"\n  }), \"Bessel's correction\"), \")\"), mdx(\"p\", null, \"$$ \\\\bar{x}_i = \\\\frac{(i-1) \\\\times \\\\bar{x}\", \"_\", \"{i-1} + x\", \"_\", \"i}{i} $$\"), mdx(\"p\", null, \"Starting with $\\\\bar{x}_1 = 0$. Note that we \\\"start\\\" from $1$ to avoid division by zero. Think of it as counting the number of observations so far. We can't calculate anything until we've seen at least one anyway. Simple python example:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"import random;  \\nmean_prev = 0;\\ni = 0;\\n\\nfor x in [random.uniform(-10,10) for _ in range(10)]:\\n    i += 1\\n    mean = ((i-1) * mean_prev + x) / i;\\n    mean_prev = mean;\\n    print(\\\"[{:d}] x={:.2f}, mean={:.2f}\\\".format(i, x, mean))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-:title=output\"\n  }), \"[1] x=-0.55, mean=-0.55\\n[2] x=-4.28, mean=-2.41\\n[3] x=9.66, mean=1.61\\n[4] x=7.60, mean=3.11\\n[5] x=-4.35, mean=1.62\\n[6] x=8.14, mean=2.70\\n[7] x=-8.69, mean=1.08\\n[8] x=-6.55, mean=0.12\\n[9] x=7.41, mean=0.93\\n[10] x=6.21, mean=1.46\\n\")), mdx(\"h4\", null, \"Recursive variance and standard deviation\"), mdx(\"p\", null, \"To calculate the variance, we also need the sum of the squares of the of the data points from $0..i$.\"), mdx(\"p\", null, \"$$ \\\\sigma^2\", \"_\", \"i = \\\\frac{\\\\sum x^2_i}{i} - \\\\bar{x}^2\", \"_\", \"i $$\"), mdx(\"p\", null, \"Then the standard deviation is simply the square root of the variance.\"), mdx(\"p\", null, \"$$ \\\\sigma\", \"_\", \"i = \\\\sqrt{\\\\sigma^2\", \"_\", \"i} $$\"), mdx(\"p\", null, \"It is simple to add this into our python sample:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"import random;\\nimport math;\\nmean_prev = 0;\\nsum_sq = 0;\\ni = 0;\\n\\nfor x in [random.uniform(-10,10) for _ in range(10)]:\\n    i += 1\\n    mean = ((i-1) * mean_prev + x) / i;\\n    sum_sq += (x-mean)**2;\\n    var = sum_sq / i;\\n    std = math.sqrt(var)\\n    mean_prev = mean;\\n\\n    print(\\\"[{:d}] x={:.2f}, mean={:.2f}, std={:.2f}\\\".format(i, x, mean, std))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-:title=output\"\n  }), \"[1] x=-9.89, mean=-9.89, std=0.00\\n[2] x=4.05, mean=-2.92, std=4.93\\n[3] x=1.69, mean=-1.38, std=4.40\\n[4] x=-2.57, mean=-1.68, std=3.83\\n[5] x=1.94, mean=-0.96, std=3.67\\n[6] x=6.77, mean=0.33, std=4.26\\n[7] x=9.95, mean=1.71, std=5.02\\n[8] x=-7.99, mean=0.49, std=5.57\\n[9] x=-5.04, mean=-0.12, std=5.51\\n[10] x=-6.69, mean=-0.78, std=5.55\\n\")), mdx(\"p\", null, \"And that's all there is to calculating the most common stream statistics.\"), mdx(\"h4\", null, \"Addendum: Recursive estimate of the covariance\"), mdx(\"p\", null, \"Something I've also had to deal with in multivariate streams is a recursive estimate of the covariance matrix. Fortunately we can do this using the means we have already calculated.\\nI repeat that this provides an \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"estimation\"), \" of the sample covariance - you will obviously calculate a different covariance matrix if you took all the points and calculated it classically. But if you can fit all points in memory then what's the point of doing this?\"), mdx(\"p\", null, \"$$\\nC_i(x,y) = C\", \"_\", \"{i-1} (x,y) \\\\cdot (i-1) + \\\\frac{(x\", \"_\", \"i - \\\\bar{x}\", \"_\", \"i)(y\", \"_\", \"i - \\\\bar{y}\", \"_\", \"{i-1})}{i}\\n$$\"), mdx(\"p\", null, \"Here is an example Java implementation from a stream clusterer I am writing:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-java\"\n  }), \"    private double[] totals;\\n    private double[] mean;\\n    private double[][] cov;\\n    private int      weight;\\n\\n... (Rest of class redacted) ...\\n\\n    /**\\n     * Adds the example to the cluster by updating the cluster statistics.\\n     * @param example The next stream example to be added to the cluster.\\n     */\\n    public void add(double[] example) {\\n        weight++;\\n\\n        double[] prevMean = Arrays.copyOf(mean, mean.length);\\n\\n        for(int i=0;i<example.length;i++) {\\n            totals[i] += example[i];\\n            mean[i] = totals[i] / weight;\\n\\n            for(int j=0;j<example.length;j++) {\\n                cov[i][j] = (cov[i][j] * (weight-1) + (example[i] - mean[i]) * (example[j] - prevMean[j]))/weight;\\n            }\\n        }\\n    }\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"If you ever have to process an indeterminate length stream of data, it's useful to be able to compute some basic statistics as you go. Theâ€¦","timeToRead":1,"banner":null}},"pageContext":{"slug":"/recursive-statistics-for-data-streams","formatString":"DD.MM.YYYY"}}}